{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dream Team:  Xingce Bao, Sohyeong Kim, Giulio Masinelli, Silvio Zanoli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART IV - Routing the travel\n",
    "\n",
    "In this part, we are going to build a robust routing algorithm for routing that considers risk factors. \n",
    "\n",
    "We basically used the same idea from the Part 3 and here we put a constraint over the number of availble transfers during the travel. Then among the possible routes that it founds, we choose the 5 fastest routes. \n",
    "\n",
    "Then we visualize our suggested route in the google map using Google Map API. By doing this way we can easily see how we can reach a destination from Zurich HB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by importing processed data created and stored from the previous sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the lists of stations within 10km from Z端rich HB\n",
    "station_data = pickle.load( open( \"./data/train_station_id.p\", \"rb\" ) )\n",
    "\n",
    "# Import the processed actual data containing mean and variance\n",
    "data_mean_variance_list = []\n",
    "data_mean_variance_list.append(pd.read_csv('./data/monday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/tuesday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/wednesday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/thursday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/friday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/saturday_processed.csv'))\n",
    "data_mean_variance_list.append(pd.read_csv('./data/sunday_processed.csv'))\n",
    "\n",
    "# Import the schedule of the transportation for each day\n",
    "data_schedule_list = []\n",
    "data_schedule_list.append(pd.read_csv('./data/monday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/tuesday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/wednesday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/thursday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/friday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/saturday_schedule.csv'))\n",
    "data_schedule_list.append(pd.read_csv('./data/sunday_schedule.csv'))\n",
    "\n",
    "# Import the station with multiple lines\n",
    "transfer_station_list = pickle.load( open( \"./data/transfer.p\", \"rb\" ) )\n",
    "\n",
    "# Import the adjacent matrix computed\n",
    "adj_map = pickle.load(open(\"./data/connection.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, call the functions built in the previous sections that will be needed to build a routing algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is reused from the PART 0.\n",
    "'''\n",
    "The function to compute the distance between two sets of (longtitude, latitude).\n",
    "'''\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "zurich_longtitude = 8.540192\n",
    "zurich_latitude = 47.378177\n",
    "def compute_distance(parameter,longtitude2 = zurich_longtitude,latitude2 = zurich_latitude):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    longtitude1,latitude1 = parameter\n",
    "    longtitude1 = float(longtitude1)\n",
    "    latitude1 = float(latitude1)\n",
    "    lat1 = radians(latitude1)\n",
    "    lon1 = radians(longtitude1)\n",
    "    lat2 = radians(latitude2)\n",
    "    lon2 = radians(longtitude2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is reused from the PART 3.\n",
    "'''\n",
    "This function gives the probability that P(X<x) , where X is a gamma distribution random variable\n",
    "'''\n",
    "def compute_probability(parameter,x):\n",
    "    k = parameter[0]\n",
    "    theta = parameter[1]\n",
    "    if k*theta*theta < 0.01:\n",
    "        if k*theta < x:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    dist = scipy.stats.gamma(k, 0, theta)\n",
    "    return dist.cdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is reused from the PART 3.\n",
    "'''\n",
    "Now we give the function to compute the probability that P(X<Y) where X and Y are both gamma distribution.This cannot be \n",
    "compute analytically so we use Monte Carlo simulation to simulate the probability.\n",
    "'''\n",
    "def compute_probability_sample(parameter_departure,parameter_arrival,N=1000):\n",
    "    k_arrival, theta_arrival = parameter_arrival\n",
    "    k_departure, theta_departure = parameter_departure\n",
    "    # If it never departures, k_departure will be -1, then we just give 0 for return which means there is no\n",
    "    # possibility that you catch any train from here\n",
    "    if k_departure < 0 or theta_departure < 0:\n",
    "        return 0.0\n",
    "    if np.isnan(k_departure) or np.isnan(theta_departure):\n",
    "        return 0.0\n",
    "    # Build two distribution\n",
    "    dist_arrival = scipy.stats.gamma(k_arrival, 0, theta_arrival+1e-20)\n",
    "    dist_departure = scipy.stats.gamma(k_departure, 0, theta_departure+1e-20)\n",
    "    # Draw samples\n",
    "    arrival_s = dist_arrival.rvs(size=N)\n",
    "    departure_s = dist_departure.rvs(size=N)\n",
    "    # Return the probability by simulation\n",
    "    return np.sum(arrival_s<departure_s)/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the efficiency of the routing algorithm, when we search the routes, we only consider the stations which we can use to make a transfer. There is no sense to compute the route possibility if it is not a transfer station or a destination(You won't need to achieve there). For this, we are using `transfer_station_list` and `adjacent_matrix` that were computed and stored in previous sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list for stations\n",
    "stations = [int(i) for i in station_data.station_number.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a bool list for whether it is a transfer matrix\n",
    "transfer_boolean = [(i in transfer_station_list) for i in stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 31, 33, 35, 36, 37, 39, 40, 42, 73, 74, 75, 87, 88, 89, 90, 91, 92, 93, 94, 95, 109, 113, 114, 116, 253, 529, 936, 961]\n"
     ]
    }
   ],
   "source": [
    "# Find the station which is isolate (For increase efficiency)\n",
    "block_station_list = []\n",
    "for block_index,block_station in enumerate([np.count_nonzero(i-1e9) for i in list(adj_map)]):\n",
    "    if block_station == 0:\n",
    "        block_station_list.append(block_index)\n",
    "print(block_station_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we defined functions that are specific for the routing algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_route_map(departure_station,arrival_station):\n",
    "    departure_index = -1\n",
    "    arrival_index = -1\n",
    "    max_depth = 4\n",
    "    # Get the index from the train number\n",
    "    for i,station in enumerate(stations):\n",
    "        if station == departure_station:\n",
    "            departure_index = i\n",
    "        if station == arrival_station:\n",
    "            arrival_index = i\n",
    "        if (departure_index != -1) and (arrival_index != -1):\n",
    "            break\n",
    "    # If it is a isolate station, return no route find\n",
    "    if departure_index in block_station_list or arrival_index in block_station_list:\n",
    "        return -1\n",
    "    print (\"index\",departure_index,arrival_index)\n",
    "    # Whether already found the solution\n",
    "    flag = 0\n",
    "    # Change all 10 to 1 (In this function, we do not care it is walk or public transport)\n",
    "    adj_map_ = adj_map.copy()\n",
    "    adj_map_[adj_map_==10.0]=1.0\n",
    "    # Initialize the result\n",
    "    result = np.array([[departure_station]])\n",
    "    final_list_depth = []\n",
    "    if adj_map_[departure_index,arrival_index]==1:\n",
    "        #final_list_depth.append(result)\n",
    "        max_depth = 2\n",
    "        flag = 1\n",
    "        #print (final_list_depth)\n",
    "    # Set the transfer and the arrival as 1 (The other station we do not care)\n",
    "    transfer_int = np.array(transfer_boolean).astype(np.int).copy()\n",
    "    transfer_int[arrival_index] = 1.0\n",
    "    # Depth of this search\n",
    "    depth = 0\n",
    "\n",
    "    final_list = []\n",
    "    while True:\n",
    "        depth = depth +1\n",
    "        print (depth)\n",
    "        result_temp_list = []\n",
    "        #print (result)\n",
    "        for i in range(result.shape[0]):\n",
    "            # Get departure station index\n",
    "            departure_station = result[i,-1]\n",
    "            for j,station in enumerate(stations):\n",
    "                if station == departure_station:\n",
    "                    departure_index = j\n",
    "                    break\n",
    "\n",
    "            # Find the station can be reached\n",
    "            this_level_station = (adj_map_[departure_index,:] == 1.0).astype(int)*transfer_int\n",
    "            if this_level_station[arrival_index] == 1:\n",
    "                # If we found the station, then set the flag = 1 and also update the max_depth \n",
    "                # Do not find the transfer which is more than 2 than the shortest transfer\n",
    "                # People won't take the train has too much transfer \n",
    "                if flag==0:\n",
    "                    max_depth = depth + 2\n",
    "                flag = 1\n",
    "                final_list.append(result[i,:].reshape(1,-1))\n",
    "            # Prepare the data of the next level\n",
    "            this_level_station[arrival_index] == 0\n",
    "            station_temp = np.array(stations)[this_level_station.astype(bool)]\n",
    "            result_temp = np.repeat(result[i,:].reshape(1,-1),len(station_temp.tolist()),axis = 0)\n",
    "            result_temp = np.concatenate([result_temp,station_temp.reshape(-1,1)], axis = 1)\n",
    "            result_temp_list.append(result_temp)\n",
    "        if flag == 1:\n",
    "            final_list_depth.append(np.concatenate(final_list,axis = 0))\n",
    "            final_list = []\n",
    "        #print('result_temp: ',result_temp_list)\n",
    "        # If already no more transfer, then return\n",
    "        if result_temp_list == []:\n",
    "            return final_list_depth\n",
    "        result = np.concatenate(result_temp_list,axis = 0)\n",
    "        print('max_depth: ',max_depth)\n",
    "        # If greater than max_depth, then return\n",
    "        if depth == min(4,max_depth):\n",
    "            return final_list_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_one_line(start_time,route,destination,probability,dayofweek,walk_speed = 1.75):\n",
    "    # Departure time is precise \n",
    "    time_list_mean = [start_time]\n",
    "    time_list_var = [0.01]\n",
    "    connect_info = []\n",
    "    # Pass every step of the route\n",
    "    for departure_station,arrival_station in zip(route,route[1:]+[destination]):\n",
    "        departure_index = -1\n",
    "        arrival_index = -1\n",
    "        # Find the departure and arrival index\n",
    "        for i,station in enumerate(stations):\n",
    "            if station == departure_station:\n",
    "                departure_index = i\n",
    "            if station == arrival_station:\n",
    "                arrival_index = i\n",
    "            if (departure_index != -1) and (arrival_index != -1):\n",
    "                break\n",
    "        if adj_map[departure_index,arrival_index] == 1.0:#walk\n",
    "            # Compute the walking time\n",
    "            pos1 = station_data[station_data.station_number == str(departure_station).zfill(7)][[\"longtitude\",\"latitude\"]].as_matrix()[0]\n",
    "            pos2 = station_data[station_data.station_number == str(arrival_station).zfill(7)][[\"longtitude\",\"latitude\"]].as_matrix()[0]\n",
    "            d = compute_distance((float(pos1[0]),float(pos1[1])),float(pos2[0]),float(pos2[1]))\n",
    "            walking_time = d*1000/walk_speed\n",
    "            # Shift the mean and do not shift the variance\n",
    "            mean = time_list_mean[-1]+walking_time\n",
    "            var = time_list_var[-1]\n",
    "            time_list_mean.append(mean)\n",
    "            time_list_var.append(var)\n",
    "            connect_info.append((-1,-1, mean, var))\n",
    "        if adj_map[departure_index,arrival_index] == 10.0:#transport\n",
    "            # Filter only keeps the data with relevant day\n",
    "            data_mean_variance = data_mean_variance_list[dayofweek]\n",
    "            data_schedule = data_schedule_list[dayofweek]\n",
    "            # Find the connection between the station\n",
    "            depart_train = data_schedule[data_schedule.station_id == departure_station]\n",
    "            arrival_train = data_schedule[data_schedule.station_id == arrival_station]\n",
    "            connect_train = pd.merge(depart_train, arrival_train, how=\"inner\",on=[\"train_number\",\"line_id\"])\n",
    "            connect_train = connect_train[connect_train.departuretimeoffsetschedule_x < connect_train.arrivaltimeoffsetschedule_y]\n",
    "            connect_train_distribution = pd.merge(connect_train, data_mean_variance[data_mean_variance.station_id==departure_station], \\\n",
    "                                                  how=\"left\",on=[\"train_number\",\"line_id\"])\n",
    "            if connect_train_distribution.shape[0]==0:\n",
    "                return -1\n",
    "            # Compute the possibility of the transfer\n",
    "            theta = time_list_var[-1]/time_list_mean[-1]\n",
    "            k = time_list_mean[-1]/theta\n",
    "            connect_train_distribution = connect_train_distribution[connect_train_distribution.departure_k>0]\n",
    "            connect_train_distribution = connect_train_distribution[connect_train_distribution.departure_theta>0]\n",
    "            train_frame_probability_temp = connect_train_distribution[['departure_k','departure_theta']].apply(compute_probability_sample, axis=1,args=((k,theta),))\n",
    "            # Keep the train which satisify the probability low bound\n",
    "            if train_frame_probability_temp.shape[0]==0:\n",
    "                return -1\n",
    "            connect_train_distribution = connect_train_distribution[train_frame_probability_temp>probability]\n",
    "            connect_train_distribution = connect_train_distribution.sort_values(by = ['line_id',\"departuretimeoffsetschedule_y\"])\n",
    "            connect_train_distribution = connect_train_distribution.drop_duplicates(subset = [\"line_id\"])\n",
    "            if connect_train_distribution.shape[0] == 0:\n",
    "                return -1\n",
    "            connect_train_distribution = connect_train_distribution[[\"train_number\",\"line_id\"]]\n",
    "            final = pd.merge(connect_train_distribution, data_mean_variance[data_mean_variance.station_id==arrival_station], \\\n",
    "                                                  how=\"left\",on=[\"train_number\",\"line_id\"])\n",
    "            # Save the information\n",
    "            final = final.sort_values(by = [\"avg(arrivaltimeoffset)\"])\n",
    "            train_number = final.at[0,\"train_number\"]\n",
    "            line_id = final.at[0,\"line_id\"]\n",
    "            mean = final.at[0,\"avg(arrivaltimeoffset)\"]\n",
    "            var = final.at[0,\"var(arrivaltimeoffset)\"]\n",
    "            connect_info.append((train_number,line_id, mean, var))\n",
    "            time_list_mean.append(mean)\n",
    "            time_list_var.append(var)\n",
    "            if np.isnan(mean) or np.isnan(var):\n",
    "                return -1\n",
    "    return connect_info\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_route(departure_station,arrival_station,departure_time,probability):\n",
    "    # Change the data to pandas datatime\n",
    "    time = pd.to_datetime(departure_time,dayfirst=True)\n",
    "    dayofweek = time.dayofweek\n",
    "    start_second = time.timestamp()%(24*3600)\n",
    "    route = find_route_map(departure_station,arrival_station)\n",
    "    info_list = []\n",
    "    info_list_station =[]\n",
    "    for depth_route in route:\n",
    "        for i in range(depth_route.shape[0]):\n",
    "            r = depth_route[i]\n",
    "            info_list_station.append(r)\n",
    "            print (r)\n",
    "            info = check_one_line(start_second,list(r),arrival_station,probability,dayofweek,walk_speed = 1.75)\n",
    "            if(len(info_list) != 0) and (info != -1):\n",
    "                print(info)\n",
    "                prev_info = info[0][1][-3:] # first transport_line\n",
    "                for next_info in info[1:]:\n",
    "                    if(next_info[0]!= -1): # if it is not a walking \n",
    "                        if(prev_info == next_info[1][-3:]):\n",
    "                            print(prev_info, next_info[1][-3:])\n",
    "                            info = -1\n",
    "                    \n",
    "            if(info == -1):\n",
    "                info_list_station.pop(-1)\n",
    "            else:\n",
    "                info_list.append(info)\n",
    "                \n",
    "    print('Finished finding Routes\\n')\n",
    "    return info_list, info_list_station\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of routing to some destinations\n",
    "\n",
    "Here is the example of the possible travel we can do from Z端rich HB(8503000) to another destination. \n",
    "\n",
    "1. \n",
    "   - Destination : 8503001\n",
    "   - Datetime : 21.05.2018 16:15:00 \n",
    "   - Probability : 90%\n",
    "   \n",
    "2. \n",
    "    - Destination : 8503001\n",
    "    - Datetime : 06.06.2018 11:00:00 \n",
    "    - Probability : 80% \n",
    "    \n",
    "3. \n",
    "   - Destination : 8594261\n",
    "   - Datetime : 21.05.2018 16:15:00 \n",
    "   - Probability : 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting = 8503000\n",
    "ending = 8503001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first try with the first one:\n",
    "We want to get to the station whose number is 8503001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>8503001</td>\n",
       "      <td>8.488940</td>\n",
       "      <td>47.391481</td>\n",
       "      <td>Z端rich Altstetten</td>\n",
       "      <td>4.133759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_number longtitude   latitude                name  distance\n",
       "2380        8503001   8.488940  47.391481   Z端rich Altstetten  4.133759"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data[station_data.station_number==str(ending)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 10 11\n",
      "1\n",
      "max_depth:  2\n",
      "2\n",
      "max_depth:  2\n",
      "[8503000]\n",
      "[8503000 8502220]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60562.0, 2295.0), ('85:11:18565:001', 'Zug:18565:S5', 62142.0, 3670.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502221]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60896.0, 2952.0), ('85:11:18565:001', 'Zug:18565:S5', 62142.0, 3670.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502222]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 61222.0, 2729.0), ('85:11:18567:001', 'Zug:18567:S5', 63967.0, 14186.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502229]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60693.0, 2583.0), ('85:11:18565:001', 'Zug:18565:S5', 62142.0, 3670.0)]\n",
      ":S5 :S5\n",
      "[8503000 8503003]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 59741.0, 144.0), ('85:11:18362:001', 'Zug:18362:S3', 61543.0, 2836.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503006]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59688.0, 20295.0), ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)]\n",
      "[8503000 8503016]\n",
      "[('85:11:1527:002', 'Zug:1527:IC5', 60607.0, 2476.0), ('85:11:2080:001', 'Zug:2080:IR', 62193.0, 4547.0)]\n",
      "[8503000 8503020]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59367.0, 21591.0), ('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0)]\n",
      "[8503000 8503127]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 60159.0, 1887.0), ('85:11:19464:001', 'Zug:19464:S14', 62684.0, 3397.0)]\n",
      "[8503000 8503128]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), ('85:11:19464:001', 'Zug:19464:S14', 62684.0, 3397.0)]\n",
      "[8503000 8503129]\n",
      "[('85:11:18860:001', 'Zug:18860:S8', 59634.0, 1438.0), ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)]\n",
      "[8503000 8503147]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), ('85:11:18362:001', 'Zug:18362:S3', 61543.0, 2836.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503306]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60272.0, 365.0), ('85:11:18362:001', 'Zug:18362:S3', 61543.0, 2836.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503509]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 59930.0, 101.0), ('85:11:18365:001', 'Zug:18365:S3', 60837.0, 7591.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503512]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 60100.0, 108.0), ('85:11:18365:001', 'Zug:18365:S3', 60837.0, 7591.0)]\n",
      ":S3 :S3\n",
      "Finished finding Routes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_list, info_list_station = find_route(starting, ending,'21.05.2018 16:15:00',0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's order the list of possible routes by displaying first the ones that take less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTime(elem):\n",
    "    return elem[0][-1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0)], array([8503000])),\n",
       " ([('85:11:18060:001', 'Zug:18060:S', 59367.0, 21591.0),\n",
       "   ('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0)],\n",
       "  array([8503000, 8503020])),\n",
       " ([('85:11:18060:001', 'Zug:18060:S', 59688.0, 20295.0),\n",
       "   ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)],\n",
       "  array([8503000, 8503006])),\n",
       " ([('85:11:18860:001', 'Zug:18860:S8', 59634.0, 1438.0),\n",
       "   ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)],\n",
       "  array([8503000, 8503129])),\n",
       " ([('85:11:1527:002', 'Zug:1527:IC5', 60607.0, 2476.0),\n",
       "   ('85:11:2080:001', 'Zug:2080:IR', 62193.0, 4547.0)],\n",
       "  array([8503000, 8503016])),\n",
       " ([('85:11:18961:001', 'Zug:18961:S9', 60159.0, 1887.0),\n",
       "   ('85:11:19464:001', 'Zug:19464:S14', 62684.0, 3397.0)],\n",
       "  array([8503000, 8503127])),\n",
       " ([('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0),\n",
       "   ('85:11:19464:001', 'Zug:19464:S14', 62684.0, 3397.0)],\n",
       "  array([8503000, 8503128]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_info = list(zip(info_list,info_list_station))\n",
    "full_info.sort(key = getTime)\n",
    "full_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only the 5 fastest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full_info)>5:\n",
    "    full_info = full_info[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the information about the means of transportation used (if by walk or using the public transportation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit', 'transit']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howImove = []\n",
    "lines = []\n",
    "for line in full_info:\n",
    "    line_info = line[0]\n",
    "    means = []\n",
    "    for i in range(len(line_info)):\n",
    "        if line_info[i][0] == -1 and line_info[i][1] == -1:\n",
    "            means.append('walk')\n",
    "        else:\n",
    "            means.append('transit')\n",
    "    howImove.append(means)\n",
    "    myLine = list(line[-1])\n",
    "    myLine.append(ending)\n",
    "    lines.append(myLine)\n",
    "howImove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now retrieve the latitude and longitude for each station in every route computeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stations = []\n",
    "for line in lines:\n",
    "    lineStations = []\n",
    "    for stat in line:\n",
    "        \n",
    "        (lat, long) = float(station_data[station_data['station_number']==str(stat)]['latitude'].item()),\\\n",
    "                    float(station_data[station_data['station_number']==str(stat)]['longtitude'].item())\n",
    "        lineStations.append((lat,long))\n",
    "    \n",
    "    Stations.append(lineStations)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(47.378177, 8.540192), (47.391481, 8.48894)],\n",
       " [(47.378177, 8.540192), (47.385195, 8.517106), (47.391481, 8.48894)],\n",
       " [(47.378177, 8.540192), (47.411529, 8.544115), (47.391481, 8.48894)],\n",
       " [(47.378177, 8.540192), (47.412717, 8.591911), (47.391481, 8.48894)],\n",
       " [(47.378177, 8.540192), (47.450383, 8.562386), (47.391481, 8.48894)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revert the list since we want to display the fastest on top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['transit', 'transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit', 'transit'],\n",
       " ['transit']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howImove.reverse()\n",
    "howImove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use gmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps\n",
    "key = 'AI...'\n",
    " if key == 'AI...':\n",
    "    raise Exception('You need to put your Gmap key here!')\n",
    "gmaps.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the first five routes proposed by the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a33423fa449a1924adfa09699d2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure(center=(47.378177, 8.540192), zoom_level=12)\n",
    "\n",
    "colors = ['blue', 'green', 'black', 'purple', 'red']\n",
    "\n",
    "a = 0\n",
    "\n",
    "  \n",
    "for stat in reversed(Stations):\n",
    "    for i in range(len(stat)):\n",
    "        travel = stat[i:2+i] if len(stat[i:2+i]) > 1 else []\n",
    "        \n",
    "        if travel != []:\n",
    "            \n",
    "            if(howImove[a][i] == 'transit'):\n",
    "                #print(colors[a])\n",
    "                station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='TRANSIT', show_markers=False)\n",
    "            else:\n",
    "                if (howImove[a][i]=='walk'):\n",
    "                    print('walk')\n",
    "                    station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='WALKING', show_markers=False)\n",
    "                    \n",
    "    \n",
    "            fig.add_layer(station2station)\n",
    "    a = a+1\n",
    "\n",
    "symbols = gmaps.symbol_layer(\n",
    "        [Stations[0][0], Stations[0][1]], fill_color=['blue', 'red'], scale = 7, stroke_color=['blue', 'red'] )\n",
    "\n",
    "fig.add_layer(symbols)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the captured image for above cell. \n",
    "\n",
    "<img src=\"./images/route1.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the train number, line id, the mean time of arrival and variance for each of the stations reached during every route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0)],\n",
       " [('85:11:18060:001', 'Zug:18060:S', 59367.0, 21591.0),\n",
       "  ('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0)],\n",
       " [('85:11:18060:001', 'Zug:18060:S', 59688.0, 20295.0),\n",
       "  ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)],\n",
       " [('85:11:18860:001', 'Zug:18860:S8', 59634.0, 1438.0),\n",
       "  ('85:11:19462:001', 'Zug:19462:S14', 60874.0, 1932.0)],\n",
       " [('85:11:1527:002', 'Zug:1527:IC5', 60607.0, 2476.0),\n",
       "  ('85:11:2080:001', 'Zug:2080:IR', 62193.0, 4547.0)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] for i in full_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again with the second example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 10 11\n",
      "1\n",
      "max_depth:  2\n",
      "2\n",
      "max_depth:  2\n",
      "[8503000]\n",
      "[8503000 8502220]\n",
      "[('85:11:18540:001', 'Zug:18540:S5', 40748.0, 1143.0), ('85:11:18543:001', 'Zug:18543:S5', 42273.0, 1124.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502221]\n",
      "[('85:11:18540:001', 'Zug:18540:S5', 41076.0, 1131.0), ('85:11:18543:001', 'Zug:18543:S5', 42273.0, 1124.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502222]\n",
      "[('85:11:18540:001', 'Zug:18540:S5', 41393.0, 482.0), ('85:11:18545:001', 'Zug:18545:S5', 44104.0, 5824.0)]\n",
      ":S5 :S5\n",
      "[8503000 8502229]\n",
      "[('85:11:18540:001', 'Zug:18540:S5', 40873.0, 936.0), ('85:11:18543:002', 'Zug:18543:S5', 42303.0, 2557.0)]\n",
      ":S5 :S5\n",
      "[8503000 8503003]\n",
      "[('85:11:18341:001', 'Zug:18341:S3', 39949.0, 3343.0), ('85:11:18340:001', 'Zug:18340:S3', 41739.0, 7519.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503006]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59646.0, 2116.0), ('85:11:19462:001', 'Zug:19462:S14', 60885.0, 1641.0)]\n",
      "[8503000 8503016]\n",
      "[8503000 8503020]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59331.0, 1693.0), ('85:11:18360:001', 'Zug:18360:S3', 59736.0, 1665.0)]\n",
      "[8503000 8503127]\n",
      "[('85:11:18941:001', 'Zug:18941:S9', 42142.0, 2000.0), ('85:11:19444:001', 'Zug:19444:S14', 44697.0, 2071.0)]\n",
      "[8503000 8503128]\n",
      "[('85:11:18941:001', 'Zug:18941:S9', 41944.0, 1969.0), ('85:11:19444:001', 'Zug:19444:S14', 44697.0, 2071.0)]\n",
      "[8503000 8503129]\n",
      "[('85:11:18840:001', 'Zug:18840:S8', 41632.0, 5193.0), ('85:11:19442:001', 'Zug:19442:S14', 42856.0, 359.0)]\n",
      "[8503000 8503147]\n",
      "[('85:11:18341:001', 'Zug:18341:S3', 40254.0, 3600.0), ('85:11:18340:001', 'Zug:18340:S3', 41739.0, 7519.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503306]\n",
      "[('85:11:18341:001', 'Zug:18341:S3', 40479.0, 4103.0), ('85:11:18342:001', 'Zug:18342:S3', 43516.0, 1332.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503509]\n",
      "[('85:11:18340:001', 'Zug:18340:S3', 41950.0, 5635.0), ('85:11:18345:001', 'Zug:18345:S3', 42803.0, 1600.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503512]\n",
      "[('85:11:18340:001', 'Zug:18340:S3', 42120.0, 5619.0), ('85:11:18345:001', 'Zug:18345:S3', 42803.0, 1600.0)]\n",
      ":S3 :S3\n",
      "Finished finding Routes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################Find Routes#############################\n",
    "starting = 8503000\n",
    "ending = 8503001\n",
    "info_list, info_list_station = find_route(starting, ending, '06.06.2018 11:00:00',0.8)\n",
    "###########################Order them##############################\n",
    "full_info = list(zip(info_list,info_list_station))\n",
    "full_info.sort(key = getTime)\n",
    "if len(full_info)>5:\n",
    "    full_info = full_info[0:5]\n",
    "#######################Retrieve Information########################\n",
    "howImove = []\n",
    "lines = []\n",
    "for line in full_info:\n",
    "    line_info = line[0]\n",
    "    means = []\n",
    "    for i in range(len(line_info)):\n",
    "        if line_info[i][0] == -1 and line_info[i][1] == -1:\n",
    "            means.append('walk')\n",
    "        else:\n",
    "            means.append('transit')\n",
    "    howImove.append(means)\n",
    "    myLine = list(line[-1])\n",
    "    myLine.append(ending)\n",
    "    lines.append(myLine)\n",
    "\n",
    "Stations = []\n",
    "for line in lines:\n",
    "    lineStations = []\n",
    "    for station in line:\n",
    "        \n",
    "        (lat, long) = float(station_data[station_data['station_number']==str(station)]['latitude'].item()),\\\n",
    "                    float(station_data[station_data['station_number']==str(station)]['longtitude'].item())\n",
    "        lineStations.append((lat,long))\n",
    "    \n",
    "    Stations.append(lineStations)\n",
    "howImove.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing information\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('85:11:18340:001', 'Zug:18340:S3', 41739.0, 7519.0)],\n",
       " [('85:11:18840:001', 'Zug:18840:S8', 41632.0, 5193.0),\n",
       "  ('85:11:19442:001', 'Zug:19442:S14', 42856.0, 359.0)],\n",
       " [('85:11:18941:001', 'Zug:18941:S9', 42142.0, 2000.0),\n",
       "  ('85:11:19444:001', 'Zug:19444:S14', 44697.0, 2071.0)],\n",
       " [('85:11:18941:001', 'Zug:18941:S9', 41944.0, 1969.0),\n",
       "  ('85:11:19444:001', 'Zug:19444:S14', 44697.0, 2071.0)],\n",
       " [('85:11:18060:001', 'Zug:18060:S', 59331.0, 1693.0),\n",
       "  ('85:11:18360:001', 'Zug:18360:S3', 59736.0, 1665.0)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Routing information')\n",
    "[i[0] for i in full_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dea1ab4f9740a7b63539f42e927e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure(center=(47.378177, 8.540192), zoom_level=12)\n",
    "\n",
    "colors = ['blue', 'green', 'black', 'purple', 'red']\n",
    "\n",
    "a = 0\n",
    "\n",
    "  \n",
    "for stat in reversed(Stations):\n",
    "    for i in range(len(stat)):\n",
    "        travel = stat[i:2+i] if len(stat[i:2+i]) > 1 else []\n",
    "        \n",
    "        if travel != []:\n",
    "            \n",
    "            if(howImove[a][i] == 'transit'):\n",
    "                #rint(colors[a])\n",
    "                station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='TRANSIT', show_markers=False)\n",
    "            else:\n",
    "                if (howImove[a][i]=='walk'):\n",
    "                    print('walk')\n",
    "                    station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='WALKING', show_markers=False)\n",
    "                    \n",
    "    \n",
    "            fig.add_layer(station2station)\n",
    "    a = a+1\n",
    "\n",
    "symbols = gmaps.symbol_layer(\n",
    "        [Stations[0][0], Stations[0][-1]], fill_color=['blue', 'red'], scale = 7, stroke_color=['blue', 'red'] )\n",
    "\n",
    "fig.add_layer(symbols)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the captured image for above cell. \n",
    "\n",
    "<img src=\"./images/route2.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last example.. \n",
    "\n",
    "Since these two stations are connected by so many routes, this time we are only visualizing the 3 bests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 10 1014\n",
      "1\n",
      "max_depth:  4\n",
      "2\n",
      "max_depth:  4\n",
      "3\n",
      "max_depth:  5\n",
      "4\n",
      "max_depth:  5\n",
      "[8503000 8503128 8587653]\n",
      "[8503000 8503147 8591065]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61607.0, 1718.0)]\n",
      "[8503000 8502220 8503128 8587653]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60562.0, 2295.0), ('85:11:19465:001', 'Zug:19465:S14', 62766.0, 9435.0), (-1, -1, 62790.05738697158, 9435.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8502221 8503128 8587653]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60896.0, 2952.0), ('85:11:19467:001', 'Zug:19467:S14', 64532.0, 8197.0), (-1, -1, 64556.05738697158, 8197.0), ('85:773:24551-01752-1', 'Bus:85:773:760:760', 65322.0, 6244.0)]\n",
      "[8503000 8502222 8503128 8587653]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 61222.0, 2729.0), ('85:11:19467:001', 'Zug:19467:S14', 64532.0, 8197.0), (-1, -1, 64556.05738697158, 8197.0), ('85:773:24551-01752-1', 'Bus:85:773:760:760', 65322.0, 6244.0)]\n",
      "[8503000 8502229 8503128 8587653]\n",
      "[('85:11:18562:001', 'Zug:18562:S5', 60693.0, 2583.0), ('85:11:19465:001', 'Zug:19465:S14', 62766.0, 9435.0), (-1, -1, 62790.05738697158, 9435.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503001 8503128 8587653]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0), ('85:11:19463:001', 'Zug:19463:S14', 60900.0, 3181.0), (-1, -1, 60924.05738697158, 3181.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503001 8503147 8591065]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 59703.0, 945.0), ('85:11:18365:001', 'Zug:18365:S3', 61895.0, 8077.0), (-1, -1, 61899.00519845217, 8077.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503003 8503128 8587653]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 59741.0, 144.0), ('85:11:18963:001', 'Zug:18963:S9', 61785.0, 5756.0), (-1, -1, 61809.05738697158, 5756.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503003 8503147 8591065]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 59741.0, 144.0), ('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61607.0, 1718.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503006 8503128 8587653]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59688.0, 20295.0), ('85:11:18963:001', 'Zug:18963:S9', 61785.0, 5756.0), (-1, -1, 61809.05738697158, 5756.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503006 8503147 8591065]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59688.0, 20295.0), ('85:11:18963:001', 'Zug:18963:S9', 61565.0, 3414.0), (-1, -1, 61569.00519845217, 3414.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      "[8503000 8503009 8591081 8591065]\n",
      "[8503000 8503010 8591058 8591065]\n",
      "[8503000 8503010 8591059 8591065]\n",
      "[8503000 8503011 8573710 8591065]\n",
      "[8503000 8503020 8503128 8587653]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59367.0, 21591.0), ('85:11:18963:001', 'Zug:18963:S9', 61785.0, 5756.0), (-1, -1, 61809.05738697158, 5756.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503020 8503147 8591065]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59367.0, 21591.0), ('85:11:18365:001', 'Zug:18365:S3', 61895.0, 8077.0), (-1, -1, 61899.00519845217, 8077.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      "[8503000 8503127 8503128 8587653]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 60159.0, 1887.0), ('85:11:18964:001', 'Zug:18964:S9', 60668.0, 1101.0), (-1, -1, 60692.05738697158, 1101.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      ":S9 :S9\n",
      "[8503000 8503127 8503147 8591065]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 60159.0, 1887.0), ('85:11:18964:001', 'Zug:18964:S9', 60862.0, 1420.0), (-1, -1, 60866.00519845217, 1420.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61607.0, 1718.0)]\n",
      ":S9 :S9\n",
      "[8503000 8503128 8503147 8591065]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), ('85:11:18964:001', 'Zug:18964:S9', 60862.0, 1420.0), (-1, -1, 60866.00519845217, 1420.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61607.0, 1718.0)]\n",
      ":S9 :S9\n",
      "[8503000 8503128 8587653 8590550]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 59976.05738697158, 1436.0), ('85:773:24254-01752-1', 'Bus:85:773:760:760', 60319.0, 3104.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503128 8587653 8590575]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 59976.05738697158, 1436.0), ('85:773:16211-05752-1', 'Bus:85:773:748:748', 61289.0, 399.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503128 8587653 8590577]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 59976.05738697158, 1436.0), ('85:773:24501-01752-1', 'Bus:85:773:748:748', 60480.0, 1406.0), ('85:773:24291-01752-1', 'Bus:85:773:760:760', 60817.0, 2587.0)]\n",
      "[8503000 8503128 8587653 8590591]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 59976.05738697158, 1436.0), ('85:773:24501-01752-1', 'Bus:85:773:748:748', 60439.0, 1043.0), ('85:773:24291-01752-1', 'Bus:85:773:760:760', 60817.0, 2587.0)]\n",
      "[8503000 8503128 8587653 8591065]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 59976.05738697158, 1436.0), ('85:773:24428-01752-1', 'Bus:85:773:752:752', 68589.0, 3493.0), ('85:773:24298-01752-1', 'Bus:85:773:760:760', 69707.0, 10559.0)]\n",
      "[8503000 8503128 8587653 8596113]\n",
      "[8503000 8503128 8590548 8590575]\n",
      "[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0), (-1, -1, 60007.86271463184, 1436.0), ('85:773:526829-01733-1', 'Bus:85:773:759:759', 60446.0, 4955.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503129 8503128 8587653]\n",
      "[('85:11:18860:001', 'Zug:18860:S8', 59634.0, 1438.0), ('85:11:19463:001', 'Zug:19463:S14', 60900.0, 3181.0), (-1, -1, 60924.05738697158, 3181.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503129 8587655 8590575]\n",
      "[('85:11:18860:001', 'Zug:18860:S8', 59634.0, 1438.0), (-1, -1, 59660.79702076582, 1438.0), ('85:773:527033-01733-1', 'Bus:85:773:759:759', 61162.0, 10548.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503129 8587655 8591065]\n",
      "[8503000 8503147 8503128 8587653]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), ('85:11:18963:001', 'Zug:18963:S9', 61785.0, 5756.0), (-1, -1, 61809.05738697158, 5756.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503147 8591065 8587653]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:24565-01752-1', 'Bus:85:773:752:752', 67090.0, 4569.0), ('85:773:24553-01752-1', 'Bus:85:773:760:760', 67956.0, 824.0)]\n",
      "[8503000 8503147 8591065 8590550]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:16091-05752-1', 'Bus:85:773:752:752', 60819.0, 382.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503147 8591065 8590575]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:16091-05752-1', 'Bus:85:773:752:752', 60689.0, 1484.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503147 8591065 8590577]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61854.0, 4270.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503147 8591065 8590591]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60048.0, 415.0), (-1, -1, 60052.00519845217, 415.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61937.0, 7870.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503147 8591065 8596113]\n",
      "[8503000 8503306 8503147 8591065]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60272.0, 365.0), ('85:11:18362:001', 'Zug:18362:S3', 60487.0, 2138.0), (-1, -1, 60491.00519845217, 2138.0), ('85:773:24292-01752-1', 'Bus:85:773:760:760', 61607.0, 1718.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503306 8588314 8587653]\n",
      "[8503000 8503306 8588314 8590575]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60272.0, 365.0), (-1, -1, 60284.682898431325, 365.0), ('85:773:24559-01752-1', 'Bus:85:773:748:748', 61103.0, 9651.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503306 8588314 8590577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('85:11:18363:002', 'Zug:18363:S3', 60272.0, 365.0), (-1, -1, 60284.682898431325, 365.0), ('85:773:24559-01752-1', 'Bus:85:773:748:748', 61009.0, 8604.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503306 8588314 8590591]\n",
      "[('85:11:18363:002', 'Zug:18363:S3', 60272.0, 365.0), (-1, -1, 60284.682898431325, 365.0), ('85:773:24559-01752-1', 'Bus:85:773:748:748', 61058.0, 8178.0), ('85:773:24255-01752-1', 'Bus:85:773:760:760', 61733.0, 5868.0)]\n",
      "[8503000 8503310 8503128 8587653]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59904.0, 20801.0), ('85:11:18963:001', 'Zug:18963:S9', 61785.0, 5756.0), (-1, -1, 61809.05738697158, 5756.0), ('85:773:24293-01752-1', 'Bus:85:773:760:760', 63501.0, 3427.0)]\n",
      "[8503000 8503310 8503147 8591065]\n",
      "[('85:11:18060:001', 'Zug:18060:S', 59904.0, 20801.0), ('85:11:18963:001', 'Zug:18963:S9', 61565.0, 3414.0), (-1, -1, 61569.00519845217, 3414.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      "[8503000 8503310 8590620 8591065]\n",
      "[8503000 8503311 8503128 8587653]\n",
      "[('85:11:18962:002', 'Zug:18962:S9', 60716.0, 6002.0), ('85:11:18965:002', 'Zug:18965:S9', 63636.0, 14827.0), (-1, -1, 63660.05738697158, 14827.0), ('85:773:24257-01752-1', 'Bus:85:773:760:760', 64401.0, 8504.0)]\n",
      ":S9 :S9\n",
      "[8503000 8503311 8503147 8591065]\n",
      "[('85:11:18962:002', 'Zug:18962:S9', 60716.0, 6002.0), ('85:11:18965:002', 'Zug:18965:S9', 63426.0, 14069.0), (-1, -1, 63430.00519845217, 14069.0), ('85:773:24294-01752-1', 'Bus:85:773:760:760', 64306.0, 997.0)]\n",
      ":S9 :S9\n",
      "[8503000 8503509 8503147 8591065]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 59930.0, 101.0), ('85:11:18365:001', 'Zug:18365:S3', 61895.0, 8077.0), (-1, -1, 61899.00519845217, 8077.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      ":S3 :S3\n",
      "[8503000 8503512 8503147 8591065]\n",
      "[('85:11:18360:002', 'Zug:18360:S3', 60100.0, 108.0), ('85:11:18365:001', 'Zug:18365:S3', 61895.0, 8077.0), (-1, -1, 61899.00519845217, 8077.0), ('85:773:24256-01752-1', 'Bus:85:773:760:760', 62505.0, 2014.0)]\n",
      ":S3 :S3\n",
      "Finished finding Routes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################Find Routes#############################\n",
    "starting = 8503000\n",
    "ending = 8594261\n",
    "info_list, info_list_station = find_route(starting, ending, '21.05.2018 16:15:00',0.9)\n",
    "###########################Order them##############################\n",
    "full_info = list(zip(info_list,info_list_station))\n",
    "full_info.sort(key = getTime)\n",
    "if len(full_info)>3:\n",
    "    full_info = full_info[0:3]\n",
    "#######################Retrieve Information########################\n",
    "howImove = []\n",
    "lines = []\n",
    "for line in full_info:\n",
    "    line_info = line[0]\n",
    "    means = []\n",
    "    for i in range(len(line_info)):\n",
    "        if line_info[i][0] == -1 and line_info[i][1] == -1:\n",
    "            means.append('walk')\n",
    "        else:\n",
    "            means.append('transit')\n",
    "    howImove.append(means)\n",
    "    myLine = list(line[-1])\n",
    "    myLine.append(ending)\n",
    "    lines.append(myLine)\n",
    "\n",
    "Stations = []\n",
    "for line in lines:\n",
    "    lineStations = []\n",
    "    for station in line:\n",
    "        \n",
    "        (lat, long) = float(station_data[station_data['station_number']==str(station)]['latitude'].item()),\\\n",
    "                    float(station_data[station_data['station_number']==str(station)]['longtitude'].item())\n",
    "        lineStations.append((lat,long))\n",
    "    \n",
    "    Stations.append(lineStations)\n",
    "howImove.reverse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing information\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0),\n",
       "  (-1, -1, 59976.05738697158, 1436.0),\n",
       "  ('85:773:24291-01752-1', 'Bus:85:773:760:760', 60817.0, 2587.0)],\n",
       " [('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0),\n",
       "  (-1, -1, 59976.05738697158, 1436.0),\n",
       "  ('85:773:24501-01752-1', 'Bus:85:773:748:748', 60480.0, 1406.0),\n",
       "  ('85:773:24291-01752-1', 'Bus:85:773:760:760', 60817.0, 2587.0)],\n",
       " [('85:11:18961:001', 'Zug:18961:S9', 59952.0, 1436.0),\n",
       "  (-1, -1, 59976.05738697158, 1436.0),\n",
       "  ('85:773:24501-01752-1', 'Bus:85:773:748:748', 60439.0, 1043.0),\n",
       "  ('85:773:24291-01752-1', 'Bus:85:773:760:760', 60817.0, 2587.0)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Routing information')\n",
    "[i[0] for i in full_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "walk\n",
      "walk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e670133dd8e46ec9754ca20b3a12f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure(center=(47.378177, 8.540192), zoom_level=12)\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "a = 0\n",
    "\n",
    "  \n",
    "for stat in reversed(Stations):\n",
    "    for i in range(len(stat)):\n",
    "        travel = stat[i:2+i] if len(stat[i:2+i]) > 1 else []\n",
    "        \n",
    "        if travel != []:\n",
    "            if(howImove[a][i] == 'transit'):\n",
    "                station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='TRANSIT', show_markers=False)\n",
    "            else:\n",
    "                if (howImove[a][i]=='walk'):\n",
    "                    print('walk')\n",
    "                    station2station = gmaps.directions_layer(travel[0], travel[1],\n",
    "                                             stroke_color=colors[a], travel_mode='WALKING', show_markers=False)\n",
    "                    \n",
    "    \n",
    "            fig.add_layer(station2station)\n",
    "    a = a+1\n",
    "\n",
    "symbols = gmaps.symbol_layer(\n",
    "        [Stations[0][0], Stations[0][-1]], fill_color=['blue', 'red'], scale = 7, stroke_color=['blue', 'red'] )\n",
    "\n",
    "fig.add_layer(symbols)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the captured image for above cell. \n",
    "\n",
    "<img src=\"./images/route3.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results, we can check the best route we had found in term of transit time (the red one) and compare it with the one outputted by Google Gmap. Hereafter is presented the first one (on Monday, departing at 16,15 from Zurich HB to Zurich Altstetten):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/route_validation1.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice that our best route overlaps with the one Google suggests. However, some of our routes are making a turistic tour of Zurich. Indeed, those routes, even if they travel a lot, are arriving earlier than the rest of the all other possible routes. It might be preferable to wait for the same direct train instead of taking other routes, however, in our algorithm we did not implement the case for waiting at the station for the next train. Hence, the algorithm will prefer to take a travel instead of waiting. \n",
    "\n",
    "Hereafter, GMap results for a route starting on Wednesday, departing at 11:00 from Zurich HB to Zurich Altstetten:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/route_validation2.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the destination is the same, some of the routes are different from the previous example since the calculated mean and variance for trip can be different from day to day. Still, our best route (red one) is the same as the one suggested by Google.\n",
    "\n",
    "Hereafter, GMap results for a route starting on Monday, departing at 16:15 from Zurich HB to Zurich D端bendorf, Hochbord Nord:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/route_validation3.jpeg\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the fastest route we've computed doesn't match with Google's suggestion. Indeed, Google suggests to take a bus which, from schedule, will take a shorter time. Our algorithm, instead, prefers to take a train. Generally, buses are more prone to be delayed by traffic, so it is more likely to arrive later than the schedule time. Since we are also considering the probability of arriving, it makes sense to suggest to take a train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:**\n",
    "\n",
    "\n",
    "The algorithm we designed both for routing and isochrone map is agnostic to the departing station hence we're not forced to start from Zurich HB.\n",
    "Cleaned dataset divided into 7 days to ensure a easier computation and modularity.\n",
    "Modularity is ensured: changing in the dataset only require to recompute the distributions, adding special days only require to load them and compute mean and variance.\n",
    "\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "\n",
    "The algorithm to compute the isochrone map could be slow due to the exponential nature of the recursive algorithm upon it was built.\n",
    "Heavily relying on GoogleMaps for visualization: nowadays is a fast-changing enviroment which is turning to a paid service.\n",
    "Not taking into account \"bank holidays\".\n",
    "\n",
    "\n",
    "**Possible improvements:**\n",
    "\n",
    "\n",
    "For the moment we only take into account, for walking, stations in a radius of 100 meters from the arrival point, it's possible to improve this by putting no-limits in the distance we can walk and optimize over it.\n",
    "The current used PDF (the gamma function) is a first guess, it can be improved with different models, for example, a Poisson distribution.\n",
    "It's possible to implement a live-version using streaming data in order to compute the distribution over a moving time window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
